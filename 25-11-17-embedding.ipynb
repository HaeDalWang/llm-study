{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 임베딩(Embedding) 첫걸음 노트북\n",
        "\n",
        "토크나이저 다음 단계로, \"토큰을 숫자 벡터로 표현\"하는 과정을 아주 기초부터 체험하는 노트입니다.\n",
        "- Step 0: 오늘 사용할 문장과 토큰 목록 정의\n",
        "- Step 1: 토큰을 숫자 ID로 바꾸는 \"사전\" 만들기\n",
        "- Step 2: One-hot 벡터로 표현해 보기\n",
        "- Step 3: Bag-of-Words(빈도 벡터) 살펴보기\n",
        "- Step 4: 임의의 임베딩 테이블을 만들어 벡터를 꺼내 보기\n",
        "- Step 5: (선택) 문장 전체를 하나의 벡터로 요약하는 간단한 방법\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0 · 실험용 문장과 토큰 목록\n",
        "- 토크나이저에서 사용했던 문장을 그대로 씁니다.\n",
        "- 토큰은 구두점 인지 토크나이저 결과 중 자주 나오는 것만 추려서 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['저의 이름 배승도에요.', '전화 번호는 010-1234-5678이에요.', 'Dobby is Free!'],\n",
              " ['[PAD]',\n",
              "  '[UNK]',\n",
              "  '저의',\n",
              "  '이름',\n",
              "  '배승도',\n",
              "  '전화',\n",
              "  '번호는',\n",
              "  '010',\n",
              "  '-',\n",
              "  '1234',\n",
              "  '5678',\n",
              "  '이에요',\n",
              "  'Dobby',\n",
              "  'is',\n",
              "  'Free',\n",
              "  '!'])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"저의 이름 배승도에요.\",\n",
        "    \"전화 번호는 010-1234-5678이에요.\",\n",
        "    \"Dobby is Free!\"\n",
        "]\n",
        "\n",
        "vocab_tokens = [\n",
        "    \"[PAD]\", \"[UNK]\", \"저의\", \"이름\", \"배승도\", \"전화\", \"번호는\", \"010\", \"-\", \"1234\", \"5678\", \"이에요\", \"Dobby\", \"is\", \"Free\", \"!\"\n",
        "]\n",
        "\n",
        "sentences, vocab_tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 · 토큰 → 숫자 ID 매핑\n",
        "- 토크나이저가 만들어 놓은 vocab을 직접 흉내 내 봅니다.\n",
        "- 사전을 만들고, 토큰이 없으면 `[UNK]` ID를 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "토큰→ID 예시:\n",
            "저의 → 2\n",
            "번호는 → 6\n",
            "없는토큰 → 1\n"
          ]
        }
      ],
      "source": [
        "token_to_id = {token: idx for idx, token in enumerate(vocab_tokens)}\n",
        "id_to_token = {idx: token for token, idx in token_to_id.items()}\n",
        "\n",
        "print(\"토큰→ID 예시:\")\n",
        "for token in [\"저의\", \"번호는\", \"없는토큰\"]:\n",
        "    print(token, \"→\", token_to_id.get(token, token_to_id[\"[UNK]\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 · One-hot 벡터 만들기\n",
        "- vocab 크기만큼 길이를 가진 벡터를 만들고, 해당 토큰 위치만 1로 표시합니다.\n",
        "- 가장 단순하지만, 희소(Sparse)하고 길이가 길다는 단점이 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'전화' one-hot 벡터 (앞부분만): [0 0 0 0 0 1 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "vocab_size = len(vocab_tokens)\n",
        "\n",
        "def one_hot(token: str) -> np.ndarray:\n",
        "    vec = np.zeros(vocab_size, dtype=int)\n",
        "    idx = token_to_id.get(token, token_to_id[\"[UNK]\"])\n",
        "    vec[idx] = 1\n",
        "    return vec\n",
        "\n",
        "sample_vector = one_hot(\"전화\")\n",
        "print(\"'전화' one-hot 벡터 (앞부분만):\", sample_vector[:12])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 · Bag-of-Words (빈도 벡터)\n",
        "- 문장 전체를 하나의 벡터로 표현하는 첫걸음.\n",
        "- 등장 횟수를 세어 벡터에 기록합니다 (순서는 무시).\n",
        "- 단점: 단어 순서를 잃고, 길이가 여전히 큽니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저의 이름 배승도에요.\n",
            "→ BOW 벡터(앞부분): [0 1 1 1 0 0 0 0 0 0 0 0]\n",
            "\n",
            "전화 번호는 010-1234-5678이에요.\n",
            "→ BOW 벡터(앞부분): [0 1 0 0 0 1 1 0 0 0 0 0]\n",
            "\n",
            "Dobby is Free!\n",
            "→ BOW 벡터(앞부분): [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "def bag_of_words(sentence: str) -> np.ndarray:\n",
        "    tokens = sentence.replace(\".\", \"\").replace(\"!\", \"\").split()\n",
        "    counter = Counter(tokens)\n",
        "    vec = np.zeros(vocab_size, dtype=int)\n",
        "    for token, count in counter.items():\n",
        "        idx = token_to_id.get(token, token_to_id[\"[UNK]\"])\n",
        "        vec[idx] = count\n",
        "    return vec\n",
        "\n",
        "for s in sentences:\n",
        "    print(s)\n",
        "    print(\"→ BOW 벡터(앞부분):\", bag_of_words(s)[:12])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 · 임의의 임베딩 테이블 흉내\n",
        "- 실제 모델은 학습을 통해 각 토큰에 짧은 실수 벡터(예: 768차원)를 부여합니다.\n",
        "- 여기서는 이해를 돕기 위해 3차원짜리 작은 테이블을 직접 만들어 봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "embedding_dim = 3\n",
        "\n",
        "embedding_table = {\n",
        "    token: np.round(np.random.uniform(-1, 1, embedding_dim), 3)\n",
        "    for token in vocab_tokens\n",
        "}\n",
        "\n",
        "for token in [\"저의\", \"전화\", \"Free\", \"없는토큰\"]:\n",
        "    emb = embedding_table.get(token, np.zeros(embedding_dim))\n",
        "    print(token.ljust(6), \"→\", emb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5 · 문장 벡터 간단히 만들기(선택)\n",
        "- 여러 토큰 벡터를 평균 내면 “문장의 대략적인 의미 벡터”가 됩니다.\n",
        "- 실제 모델도 비슷한 아이디어를 더 정교하게 사용합니다.\n",
        "- 여기서는 Step 4의 임베딩 테이블을 이용해 평균 벡터를 계산해 봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sentence_embedding(sentence: str) -> np.ndarray:\n",
        "    tokens = sentence.replace(\".\", \"\").replace(\"!\", \"\").split()\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        vectors.append(embedding_table.get(token, np.zeros(embedding_dim)))\n",
        "    if not vectors:\n",
        "        return np.zeros(embedding_dim)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "for s in sentences:\n",
        "    print(s)\n",
        "    print(\"→ 문장 벡터:\", np.round(sentence_embedding(s), 3))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 마무리 메모\n",
        "- 토큰을 숫자 ID로 바꾸면 모델이 “사전을 공유”할 수 있습니다.\n",
        "- One-hot과 Bag-of-Words는 단순하지만 차원이 매우 큽니다.\n",
        "- 임베딩 테이블은 각 토큰에 짧은 실수 벡터를 부여해 효율적으로 표현합니다.\n",
        "- 문장 임베딩은 여러 토큰 벡터를 조합(평균 또는 가중합)해서 얻을 수 있습니다.\n",
        "- 실제 모델은 이 과정을 학습으로 자동화하며, 차원도 훨씬 크고 정보가 풍부합니다.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
