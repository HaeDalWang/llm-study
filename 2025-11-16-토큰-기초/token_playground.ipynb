{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 토큰 플레이그라운드 (Jupyter)\n",
        "\n",
        "- 이 노트북은 토큰이 뭔지 “눈으로 확인”하며 이해하기 위한 간단한 실습용입니다.\n",
        "- 아래 변수 `sample_text`, `toy_vocab`를 직접 바꿔가며 각 토큰화 방식 결과를 비교하세요.\n",
        "- `vocab`는 `vocabulary(어휘집)`의 줄임말로, “모델이 아는 토큰들의 목록”을 뜻합니다.\n",
        "- 설치가 필요 없다면 기본 파이썬으로도 동작하지만, 노트북이 더 편합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장: 해리포터는 마법사야!\n",
            "toy_vocab 수: 6\n"
          ]
        }
      ],
      "source": [
        "# 실험할 문장과 장난감 서브워드 어휘(더 짧은 예시)\n",
        "sample_text = \"해리포터는 마법사야!\"\n",
        "\n",
        "# 아주 간단한 장난감 vocab: 자주 등장한다고 가정한 조각들\n",
        "toy_vocab = [\n",
        "    \"해리포터\", \"는\", \"마법사\", \"야\", \"!\", \" \",\n",
        "]\n",
        "\n",
        "print(\"문장:\", sample_text)\n",
        "print(\"toy_vocab 수:\", len(toy_vocab))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 용어 미니사전\n",
        "- **토큰(Token)**: 문장을 모델이 다루기 쉬운 작은 단위(단어/부분 단어 등)\n",
        "- **어휘집(Vocabulary, vocab)**: 모델이 아는 토큰의 목록\n",
        "- **토크나이저(Tokenizer)**: 문장을 토큰 목록으로 바꾸는 도구"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def tokenize_whitespace(text: str) -> List[str]:\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def tokenize_characters(text: str) -> List[str]:\n",
        "    return list(text)\n",
        "\n",
        "\n",
        "def tokenize_punct_aware(text: str) -> List[str]:\n",
        "    pattern = r\"[A-Za-z0-9_]+|[\\uAC00-\\uD7A3]+|[^\\sA-Za-z0-9_\\uAC00-\\uD7A3]\"\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "\n",
        "def greedy_subword_tokenize(text: str, vocab: List[str]) -> List[str]:\n",
        "    if not text:\n",
        "        return []\n",
        "    sorted_vocab = sorted(set(vocab), key=len, reverse=True)\n",
        "    tokens: List[str] = []\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        matched = False\n",
        "        for token in sorted_vocab:\n",
        "            if text.startswith(token, i):\n",
        "                tokens.append(token)\n",
        "                i += len(token)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            tokens.append(text[i])\n",
        "            i += 1\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1. 공백 기준 토큰화\n",
        "- 바로 아래 셀을 실행해 결과를 확인하세요.\n",
        "- 헷갈리면 이 셀(설명)만 다시 읽고, 아래 코드만 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장: 해리포터는 마법사야!\n",
            "[공백 기준] 토큰 수: 2\n",
            "['해리포터는', '마법사야!']\n"
          ]
        }
      ],
      "source": [
        "print(\"문장:\", sample_text)\n",
        "ws = tokenize_whitespace(sample_text)\n",
        "print(\"[공백 기준] 토큰 수:\", len(ws))\n",
        "print(ws)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2. 문자 기준 토큰화\n",
        "- 한 글자씩 쪼갰을 때 길이가 어떻게 달라지는지 확인하세요.\n",
        "- 긴 리스트가 부담되면 미리보기(`[:50]`)만 봐도 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[문자 기준] 토큰 수: 11\n",
            "['해', '리', '포', '터', '는', ' ', '마', '법', '사', '야', '!'] \n"
          ]
        }
      ],
      "source": [
        "chars = tokenize_characters(sample_text)\n",
        "print(\"[문자 기준] 토큰 수:\", len(chars))\n",
        "print(chars[:50], (\"...\" if len(chars) > 50 else \"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3. 구두점 인지 토큰화(간단)\n",
        "- 단어/한글 블록과 기호를 분리합니다.\n",
        "- 문장 끝의 마침표, 느낌표, 영어/숫자 등이 어떻게 나뉘는지 보세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[구두점 인지] 토큰 수: 3\n",
            "['해리포터는', '마법사야', '!']\n"
          ]
        }
      ],
      "source": [
        "pn = tokenize_punct_aware(sample_text)\n",
        "print(\"[구두점 인지] 토큰 수:\", len(pn))\n",
        "print(pn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4. 장난감 서브워드\n",
        "- `toy_vocab`에 있는 조각들을 우선적으로 길게 매칭합니다.\n",
        "- `toy_vocab`에 조각을 추가/삭제하며 토큰 수 변화를 관찰하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[서브워드] 토큰 수: 6\n",
            "['해리포터', '는', ' ', '마법사', '야', '!']\n",
            "\n",
            "팁) toy_vocab에 자주 나오는 덩어리를 넣으면 토큰 수가 줄어듭니다.\n"
          ]
        }
      ],
      "source": [
        "sw = greedy_subword_tokenize(sample_text, toy_vocab)\n",
        "print(\"[서브워드] 토큰 수:\", len(sw))\n",
        "print(sw)\n",
        "\n",
        "print(\"\\n팁) toy_vocab에 자주 나오는 덩어리를 넣으면 토큰 수가 줄어듭니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 사용 팁\n",
        "- 위 첫 번째 셀의 `sample_text`, 두 번째 줄의 `toy_vocab`를 바꾸고 이 셀 위쪽부터 순서대로 실행하세요.\n",
        "- `toy_vocab`에 자주 등장하는 조각을 추가하면, 서브워드 결과 토큰 수가 줄어드는 경향을 볼 수 있습니다.\n",
        "- 이모지나 특수문자를 `sample_text`에 넣고 `구두점 인지` 결과가 어떻게 변하는지도 확인해보세요."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
